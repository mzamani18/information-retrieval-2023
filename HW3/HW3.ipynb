{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xZbwdiO7on8"
      },
      "source": [
        "# HW3 Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mXTKt_R7on-"
      },
      "source": [
        "## Import libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### `nltk`\n",
        "\n",
        "- **Description**: `Natural Language Toolkit`, I use it for tokenization, stemming , remove stop words and lemmatizer.\n",
        "\n",
        "##### `glob`\n",
        "\n",
        "- **Description**: Just for reading documents name in ./docs directory\n",
        "\n",
        "##### `string`\n",
        "\n",
        "- **Description**: I used from punctuations attribute on this package\n",
        "\n",
        "##### `json`\n",
        "\n",
        "- **Description**: For encoding and decoding inverted indexes when we want to write in disk or read from disk\n",
        "\n",
        "##### `math`\n",
        "\n",
        "- **Description**: For calculation, log and ...\n",
        "\n",
        "##### `shutil | os`\n",
        "\n",
        "- **Description**: I imported these for creating and removing disk directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MeBGYRzd7on-"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import glob\n",
        "import string\n",
        "import json\n",
        "import math\n",
        "import shutil\n",
        "import os\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `gamma code` is a universal code that is used to encode a sequence of positive integers. It is developed by Peter Elias. It is most useful when the upper-bound of integers cannot be determined beforehand and we use it for optimization on docement ids.\n",
        "\n",
        "##### Methods\n",
        "\n",
        "##### `gammaDecoder(input : str) -> int`\n",
        "\n",
        "- **Description**: i this section I get encoded gamma code and decode that and finally i will return the result as a integer.\n",
        "\n",
        "##### `gammaEncoder(input : int) -> str`\n",
        "\n",
        "- **Description**: I will encode the integer that you gave me as input\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gamma Coding And Opthional section\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GammaCoding:\n",
        "        def gammaDecoder(input : str) -> int:\n",
        "            if(input) == '0' : return 0\n",
        "\n",
        "            input = list(input) \n",
        "            k = 0\n",
        "            while input[k]=='0': \n",
        "                k += 1\n",
        "\n",
        "            input = input[k:2*k+1] \n",
        "            input.reverse() \n",
        "\n",
        "            res = 0\n",
        "            for ind, s in enumerate(input): \n",
        "                if s == '1': \n",
        "                    res += math.pow(2, ind) \n",
        "            return int(res)\n",
        "\n",
        "\n",
        "        def gammaEncoder(input : int) -> str:\n",
        "            log2 = lambda x: math.log(x, 2) \n",
        "\n",
        "            if not input:\n",
        "                return '0'\n",
        "            \n",
        "            n = int(log2(input))\n",
        "            b = input - 2**n\n",
        "\n",
        "            return n *'0'+'1' + ('{0:0%db}' % n).format(b)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Utils` class contains utility methods for set operations like intersection and union and proximity distance calculations that is a little custom function(maybe I should change it's name) and in this practice I implemeted merge and I use it.\n",
        "\n",
        "#### Methods\n",
        "\n",
        "##### `merge(l1: list, l2: list) -> list`\n",
        "\n",
        "- **Description**: This function will merge two sorted posting list, as the way that we construct our postings we know that they are sorted and $L2 < L1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Utils:\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    def merge(l1: list, l2: list)->list:\n",
        "        res = []\n",
        "        i, j =0, 0\n",
        "        while(i<len(l1) and j<len(l2)):\n",
        "            if GammaCoding.gammaDecoder(l1[i]) < GammaCoding.gammaDecoder(l2[j]) : \n",
        "                res.append(l1[i])\n",
        "                i+=1\n",
        "            else:\n",
        "                res.append(l2[j])\n",
        "                j+=1\n",
        "\n",
        "        if(i<len(l1)) : \n",
        "            res+=l1[i:]\n",
        "        else : \n",
        "            res+= l2[j:]\n",
        "\n",
        "        # save differences of doc ids for gamma coding instead of the id \n",
        "        if len(res) >1:\n",
        "            res[1] = GammaCoding.gammaEncoder(abs(GammaCoding.gammaDecoder(res[0])-GammaCoding.gammaDecoder(res[1])))\n",
        "        for i in range(2, len(res)):\n",
        "            res[i] = GammaCoding.gammaEncoder(abs((GammaCoding.gammaDecoder(res[i-1]) + GammaCoding.gammaDecoder(res[0])) - GammaCoding.gammaDecoder(res[i])))\n",
        "\n",
        "        return res     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qjC6tFE7on_"
      },
      "source": [
        "## Load Documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `LoadDocuments` class is responsible for loading and managing a collection of documents. If you want to change the document path please cgange path variable.\n",
        "\n",
        "##### Properties\n",
        "\n",
        "- **_`DOC_ID_MAPPER`_** _(class variable)_: A dictionary mapping document names to their respective IDs, Be care full, becuse it depends on your documents order and docIds started from zero.\n",
        "\n",
        "##### Methods\n",
        "\n",
        "##### `__init__(self)`\n",
        "\n",
        "- **Description**: Initializes a `LoadDocuments` object with a default path to load text that you can change it base on your docs directory path and an empty `memoryDocumentCollection`. that is a dictionary and I will set initial data of problem.\n",
        "\n",
        "##### `removeLoadedDocumentsFromMemory(self)`\n",
        "\n",
        "- **Description**: I will destruct `memoryDocumentCollection` property.\n",
        "\n",
        "##### `loadDocumentFromDisk(self)`\n",
        "\n",
        "- **Description**: Loads text documents from the disk and populates the `memoryDocumentCollection` property.\n",
        "\n",
        "##### `buildDocumentIDMapper(self)`\n",
        "\n",
        "- **Description**: Builds a document ID mapper by associating each document's name with a unique ID and populates the `DOC_ID_MAPPER` dictionary, I will print this mapper data for checking my results base on this mapper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bLflR9ig7on_"
      },
      "outputs": [],
      "source": [
        "class LoadDocuments:      \n",
        "\n",
        "    DOC_ID_MAPPER = {}\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        LoadDocuments.removeDisk()\n",
        "        LoadDocuments.createDisk()\n",
        "        self.path = \"./docs/*.txt\"\n",
        "        self.limitationNumberOfDocumentsInMemory = 3\n",
        "        self.allDocumentNames = glob.glob(self.path)\n",
        "        self.memoryDocumentCollection = {}\n",
        "        self.lastLoadedDocumentId = 0\n",
        "\n",
        "    def createDisk() -> None:\n",
        "        path = os.path.join('./', 'Disk') \n",
        "        try:\n",
        "            os.mkdir(path)\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "    def removeDisk() -> None:\n",
        "        try:\n",
        "            shutil.rmtree('./Disk')\n",
        "        except OSError:\n",
        "            pass   \n",
        "\n",
        "    def removeLoadedDocumentsFromMemory(self)->None:\n",
        "        self.memoryDocumentCollection = {}\n",
        "\n",
        "    def loadDocumentFromDisk(self)->None:\n",
        "        print(self.allDocumentNames[self.lastLoadedDocumentId : self.lastLoadedDocumentId + self.limitationNumberOfDocumentsInMemory])\n",
        "        for documentName in self.allDocumentNames[self.lastLoadedDocumentId : self.lastLoadedDocumentId + self.limitationNumberOfDocumentsInMemory] :\n",
        "            document = open(documentName, \"r\", encoding = 'cp1252')\n",
        "            self.memoryDocumentCollection[documentName] = document.read()\n",
        "        self.lastLoadedDocumentId += self.limitationNumberOfDocumentsInMemory    \n",
        "\n",
        "    def buildDocumentIDMapper(self)->None:\n",
        "        for ind, documentName in enumerate(self.memoryDocumentCollection):\n",
        "            self.DOC_ID_MAPPER[documentName] = ind + (self.lastLoadedDocumentId-self.limitationNumberOfDocumentsInMemory) + 1\n",
        "            print(\"docId : \" , ind + (self.lastLoadedDocumentId-self.limitationNumberOfDocumentsInMemory) + 1 , ' ->  docName: ', documentName[7:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3ncGZTH7on_"
      },
      "source": [
        "## Document Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `DocumentPreProcessor` class extends the functionality of the `LoadDocuments` class by providing methods to preprocess text documents. These methods perform various text processing tasks, such as converting text to lowercase, tokenization, removing punctuations, removing stop words, stemming, and lemmatization.\n",
        "\n",
        "#### Methods\n",
        "\n",
        "##### `__init__(self)`\n",
        "\n",
        "- **Description**: Initializes a `DocumentPreProcessor` object by calling the constructor of the base class `LoadDocuments`.\n",
        "\n",
        "##### `convertToLower(self)`\n",
        "\n",
        "- **Description**: Converts all text in the loaded documents to lowercase.\n",
        "\n",
        "##### `tokenizer(self)`\n",
        "\n",
        "- **Description**: Tokenizes the text in the loaded documents using a regular expression pattern.\n",
        "\n",
        "##### `removePunctuations(self)`\n",
        "\n",
        "- **Description**: Removes punctuations from the tokenized text in the loaded documents.\n",
        "\n",
        "##### `removeStopWords(self)`\n",
        "\n",
        "- **Description**: Removes stop words from the tokenized text in the loaded documents using NLTK's English stop words list.\n",
        "\n",
        "##### `stemming(self)`\n",
        "\n",
        "- **Description**: Applies stemming to the tokenized text in the loaded documents using the Porter Stemmer algorithm from NLTK.\n",
        "\n",
        "##### `lemmatizer(self)`\n",
        "\n",
        "- **Description**: Applies lemmatization to the tokenized text in the loaded documents using NLTK's WordNet Lemmatizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3bpbrLSa7on_"
      },
      "outputs": [],
      "source": [
        "class DocumentPreProcessor(LoadDocuments):\n",
        "    def __init__(self)->None:\n",
        "        super().__init__()\n",
        "\n",
        "    def convertToLower(self)->None:\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            self.memoryDocumentCollection[documentName] = document.lower()\n",
        "\n",
        "    def tokenizer(self)->None:\n",
        "        pattern = r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?|\\w+'\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            self.memoryDocumentCollection[documentName] = nltk.tokenize.regexp_tokenize(document, pattern)\n",
        "\n",
        "    def removePunctuations(self)->None:\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            for ind, term in enumerate(document):\n",
        "                self.memoryDocumentCollection[documentName][ind] = \"\".join([i for i in term if i not in string.punctuation])\n",
        "\n",
        "    def removeStopWords(self)->None:\n",
        "        stopwords = nltk.corpus.stopwords.words('english')\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            self.memoryDocumentCollection[documentName] = [i for i in document if i not in stopwords]\n",
        "\n",
        "    def stemming(self)->None:\n",
        "        porter_stemmer = nltk.stem.porter.PorterStemmer()\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            self.memoryDocumentCollection[documentName] = [porter_stemmer.stem(term) for term in document]\n",
        "\n",
        "    def lemmatizer(self)->None:\n",
        "        wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            self.memoryDocumentCollection[documentName] = [wordnet_lemmatizer.lemmatize(term) for term in document]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZONq2Dx7ooA"
      },
      "source": [
        "## Inverted Index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `InvertedIndex` class will generate a invertedIndexex that maps terms to the documents that contain them, I will save all positions for proximate search .\n",
        "\n",
        "#### Properties\n",
        "\n",
        "- **`invertedIndex`**: A dictionary representing the inverted index where terms are mapped to document IDs and their positions.\n",
        "\n",
        "#### Methods\n",
        "\n",
        "##### `__init__(self)`\n",
        "\n",
        "- **Description**: Initializes an `InvertedIndex` object and call base class constructor.\n",
        "\n",
        "##### `buildInvertedIndex(self)`\n",
        "\n",
        "- **Description**: Builds the inverted index by iterating through preprocessed documents and mapping terms to document IDs and their positions.\n",
        "\n",
        "##### `removeInvertedIndexFromMemory(self)`\n",
        "\n",
        "- **Description**: deconstruct `InvertedIndex` and remove its data from memory.\n",
        "\n",
        "##### `build(self) -> None`\n",
        "\n",
        "- **Description**: Initiates the preprocessing steps by loading documents, building document ID mapper, converting to lowercase, tokenizing, removing punctuations, removing stop words, stemming, lemmatizing, and finally, building the inverted index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3BvbHTGH7ooA"
      },
      "outputs": [],
      "source": [
        "class InvertedIndex(DocumentPreProcessor):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.invertedIndex = {}    \n",
        "\n",
        "    def buildInvertedIndex(self)->None:\n",
        "        for documentName, document in self.memoryDocumentCollection.items():\n",
        "            for ind, term in enumerate(document):\n",
        "                if term not in self.invertedIndex:\n",
        "                    self.invertedIndex[term] = []\n",
        "  \n",
        "                self.invertedIndex[term].append(GammaCoding.gammaEncoder(self.DOC_ID_MAPPER[documentName]))\n",
        "                self.invertedIndex[term] = list(set(self.invertedIndex[term]))\n",
        "\n",
        "    def removeInvertedIndexFromMemory(self)->None:            \n",
        "        self.invertedIndex = {}\n",
        "\n",
        "    def execute(self)->None:\n",
        "        self.removeLoadedDocumentsFromMemory()\n",
        "        self.removeInvertedIndexFromMemory()\n",
        "        self.loadDocumentFromDisk()\n",
        "        self.buildDocumentIDMapper()\n",
        "        self.convertToLower()\n",
        "        self.tokenizer()\n",
        "        self.removePunctuations()\n",
        "        self.removeStopWords()\n",
        "        self.stemming()\n",
        "        self.lemmatizer()\n",
        "        self.buildInvertedIndex()      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BSBI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `InvertedIndex` class will generate a invertedIndexex that maps terms to the documents that contain them, I will save all positions for proximate search .\n",
        "\n",
        "#### Properties\n",
        "\n",
        "- **`finalInvertedIndex`**: A dictionary representing the inverted index where terms are mapped to a list of document IDs, this is the final inverted index that is on memory.\n",
        "\n",
        "- **`numberOfBlocks`**: A integer representing number of all blocks that exist in disk\n",
        "\n",
        "#### Methods\n",
        "\n",
        "##### `__init__(self)`\n",
        "\n",
        "- **Description**: Initializes an `finalInvertedIndex` object and `numberOfBlocks` and call base class constructor.\n",
        "\n",
        "##### `writeToDisk(self, inputData: dict) -> None`\n",
        "\n",
        "- **Description**: Write current inverted index to disk.\n",
        "\n",
        "##### `readBlock(self, blockNo: int)-> dict`\n",
        "\n",
        "- **Description**: Read the i'th block from disk\n",
        "\n",
        "##### `build(self) -> None`\n",
        "\n",
        "- **Description**: it's a executer for BSBI that will load all blocks one by one and merge them to construct final inverted index.\n",
        "\n",
        "##### `mergeBlocks(self) | merge(self) -> None`\n",
        "\n",
        "- **Description**: It read the first block and insert it to `finalInvertedIndex` then I will read blocks one by one and merge them to `finalInvertedIndex`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BSBI(InvertedIndex):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.finalInvertedIndex = {}\n",
        "        self.numberOfBlocks = 0\n",
        "\n",
        "    def build(self) -> None:\n",
        "        while(self.lastLoadedDocumentId < len(self.allDocumentNames)):\n",
        "            self.numberOfBlocks+=1\n",
        "            self.execute()\n",
        "            self.writeToDisk(self.invertedIndex)\n",
        "\n",
        "        self.mergeBlocks()     \n",
        "\n",
        "    def writeToDisk(self, inputData: dict) -> None:\n",
        "        with open(\"./Disk/document%i.txt\"%(self.numberOfBlocks), 'w') as convert_file: \n",
        "            convert_file.write(json.dumps(inputData))\n",
        "\n",
        "    def readBlock(self, blockNo: int)-> dict:\n",
        "        with open(\"./Disk/document%i.txt\"%(blockNo), \"r\") as f: \n",
        "            data = f.read() \n",
        "        return json.loads(data) \n",
        "    \n",
        "    def merge(self, invertedIndex : dict) -> None:\n",
        "        for term, documents in invertedIndex.items():\n",
        "            if term not in self.finalInvertedIndex:\n",
        "                self.finalInvertedIndex[term] = documents\n",
        "            else:\n",
        "                self.finalInvertedIndex[term] = Utils.merge(self.finalInvertedIndex[term], documents)\n",
        "                \n",
        "    def mergeBlocks(self) -> None:\n",
        "        print(\"block numbers\" , self.numberOfBlocks)\n",
        "\n",
        "        self.finalInvertedIndex = self.readBlock(1)\n",
        "\n",
        "        for i in range(2, self.numberOfBlocks):\n",
        "            self.merge(self.readBlock(i+1))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['./docs/Jerry Decided To Buy a Gun.txt', './docs/Rentals at the Oceanside Community.txt', './docs/Gasoline Prices Hit Record High.txt']\n",
            "docId :  1  ->  docName:  Jerry Decided To Buy a Gun.txt\n",
            "docId :  2  ->  docName:  Rentals at the Oceanside Community.txt\n",
            "docId :  3  ->  docName:  Gasoline Prices Hit Record High.txt\n",
            "['./docs/Cloning Pets.txt', './docs/Crazy Housing Prices.txt', './docs/Man Injured at Fast Food Place.txt']\n",
            "docId :  4  ->  docName:  Cloning Pets.txt\n",
            "docId :  5  ->  docName:  Crazy Housing Prices.txt\n",
            "docId :  6  ->  docName:  Man Injured at Fast Food Place.txt\n",
            "['./docs/A Festival of Books.txt', './docs/Food Fight Erupted in Prison.txt', './docs/Better To Be Unlucky.txt']\n",
            "docId :  7  ->  docName:  A Festival of Books.txt\n",
            "docId :  8  ->  docName:  Food Fight Erupted in Prison.txt\n",
            "docId :  9  ->  docName:  Better To Be Unlucky.txt\n",
            "['./docs/Sara Went Shopping.txt', './docs/Freeway Chase Ends at Newsstand.txt', './docs/Trees Are a Threat.txt']\n",
            "docId :  10  ->  docName:  Sara Went Shopping.txt\n",
            "docId :  11  ->  docName:  Freeway Chase Ends at Newsstand.txt\n",
            "docId :  12  ->  docName:  Trees Are a Threat.txt\n",
            "['./docs/A Murder-Suicide.txt', './docs/Happy and Unhappy Renters.txt', './docs/Pulling Out Nine Tons of Trash.txt']\n",
            "docId :  13  ->  docName:  A Murder-Suicide.txt\n",
            "docId :  14  ->  docName:  Happy and Unhappy Renters.txt\n",
            "docId :  15  ->  docName:  Pulling Out Nine Tons of Trash.txt\n",
            "block numbers 5\n"
          ]
        }
      ],
      "source": [
        "BSBI = BSBI()\n",
        "BSBI.build()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Inverted Indes In My memory:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'jerri': ['10'], 'baldwin': ['10'], '30': ['011', '010', '00101'], 'year': ['011', '10', '010', '10', '010', '0', '0', '011', '00111', '00101', '00110'], 'old': ['10', '00110', '00101', '010', '0', '0001100', '010'], 'manag': ['011', '10', '011', '00101'], 'pizza': ['10'], 'restaur': ['10'], 'live': ['10', '00101', '011', '00100', '0001000'], 'apart': ['10', '0001101'], 'one': ['010', '10', '010', '00100', '011', '00100', '00111', '00110', '00110'], 'mile': ['011', '10', '10', '0001011'], 'north': ['10', '0001010'], 'walk': ['10'], 'work': ['011', '010', '010', '10', '0001011'], 'rain': ['10', '0001110'], 'took': ['10'], 'bu': ['10', '0001010'], 'love': ['10', '00110'], 'gangster': ['10'], 'movi': ['10', '00110'], 'new': ['10', '0001101'], 'came': ['10', '00101', '00100', '0001000', '00110', '00111'], 'would': ['010', '10', '10', '0', '10', '0001010', '011', '0001001'], 'go': ['011', '010', '00101', '10', '0001001', '010'], 'theater': ['10'], 'watch': ['10', '00101', '0001001'], 'three': ['010', '10', '0', '011', '10', '0001100'], 'four': ['010', '10', '00100', '011', '0001001'], 'time': ['011', '10', '0', '0001010', '010'], 'went': ['10', '00110', '011', '00111'], 'video': ['10', '00110'], 'buy': ['10', '0001000', '00110'], 'barney': ['10'], 'store': ['011', '010', '00101'], 'home': ['010', '10', '00100', '011', '0001001'], 'collect': ['10'], '1000': ['10', '0001011'], 'color': ['10', '0001110', '10'], 'black': ['10'], 'white': ['10'], 'english': ['10'], 'spanish': ['10'], 'japanes': ['10'], 'could': ['10', '0001100'], 'tell': ['011', '010', '0001000'], 'name': ['010', '10'], 'director': ['10', '0001110'], 'star': ['10'], 'plot': ['10'], 'say': ['10', '00110', '011', '0001001'], 'like': ['10', '00110', '00110', '00111'], 'pulp': ['10'], 'fiction': ['10'], 'well': ['10', '0001010', '00100'], 'rattl': ['10'], 'detail': ['10'], 'invit': ['10'], 'place': ['10', '0001100'], 'nice': ['10', '0001100'], 'guy': ['10', '0001101'], 'final': ['10', '0001000'], 'decid': ['10'], 'gun': ['10'], 'save': ['10', '010', '0001100'], 'money': ['011', '010', '010', '010', '00111'], 'coupl': ['10', '00101', '00111'], 'bought': ['10', '010', '00111'], 'use': ['10', '010', '0001010', '00100'], '38': ['10'], 'calib': ['10'], 'revolv': ['10'], '300': ['10'], 'also': ['010', '10', '0', '00100', '0001000'], 'box': ['10'], 'ammunit': ['10'], 'follow': ['10', '00110'], 'saturday': ['10', '00101', '0001001', '00100'], 'morn': ['10'], 'club': ['10', '0001110'], 'practic': ['10', '0001101'], '10': ['011', '010', '010', '00100', '010', '00101'], 'minut': ['011', '10'], 'accident': ['10'], 'drop': ['10'], 'pistol': ['10'], 'bullet': ['10'], 'right': ['011', '010', '00100'], 'knee': ['10'], 'limp': ['10'], 'cane': ['10'], 'oceansid': ['010'], 'commun': ['010', '0001101'], 'lozano': ['010'], 'beach': ['010'], 'debat': ['010'], 'whether': ['010'], 'allow': ['010'], 'homeown': ['010'], 'rent': ['010', '011', '0001001'], 'weekli': ['010'], 'basi': ['010'], 'summer': ['010'], 'rental': ['010'], 'produc': ['010'], 'high': ['010', '0001010'], 'incom': ['010'], 'owner': ['010', '00111'], 'citi': ['010', '00101'], 'get': ['010', '10', '010', '00100', '00100', '00111', '00101'], 'part': ['010'], '15': ['010'], 'percent': ['010', '10', '010', '011', '00100', '0001000'], 'surcharg': ['010'], 'boon': ['010'], 'coffer': ['010'], 'said': ['010', '10', '010', '00100', '00101', '010', '0001001', '00100', '0001000'], 'rick': ['010'], 'brown': ['010'], 'bring': ['010', '0001100'], '2000': ['010'], 'week': ['010', '00100', '00111'], 'howev': ['010', '0001001'], 'worm': ['010'], 'stop': ['010', '00101', '011', '00110'], 'ago': ['010', '10', '10', '10', '0001010'], 'problem': ['010', '0001010'], 'gener': ['010'], 'two': ['010', '10', '10', '10', '011', '010', '011', '0001000', '00101', '00111'], 'even': ['010', '10', '10', '0001010', '011'], 'famili': ['010'], 'pile': ['010'], 'bedroom': ['010'], 'hous': ['010', '0001011'], 'park': ['010', '011', '00110'], 'car': ['010', '10', '010', '00100', '010', '011', '0001010', '010'], 'lawn': ['010'], 'huge': ['010'], 'amount': ['010'], 'trash': ['010', '0001101'], 'sometim': ['010'], 'toss': ['010'], 'street': ['010', '00101', '011', '00110'], 'sidewalk': ['010'], 'nois': ['010'], 'anoth': ['010', '0001100'], 'peopl': ['010', '10', '010', '00101', '00110', '00110'], 'parti': ['010'], 'late': ['010'], 'loud': ['010'], 'everi': ['010', '10', '10', '0001010', '011', '0001001'], 'night': ['010', '0001011'], 'abus': ['010'], 'creat': ['010'], 'lot': ['010', '10', '0001010'], 'friction': ['010'], 'neighbor': ['010', '0001011', '10'], 'result': ['010'], 'extra': ['010', '0001010'], 'mainten': ['010'], 'crew': ['010', '0001101'], 'polic': ['010', '10', '00101', '00110', '00111', '00101'], 'respond': ['010'], 'almost': ['010', '10', '0001010', '011'], 'hourli': ['010'], 'resid': ['010', '10', '10', '00111', '011'], 'complaint': ['010'], 'music': ['010', '0001100'], 'budget': ['010'], 'make': ['010', '10', '0001001'], 'reconsid': ['010'], 'ban': ['010'], 'offici': ['010', '00100', '00110'], 'hold': ['010'], 'meet': ['010'], 'next': ['010', '0001000', '011', '0001010'], 'listen': ['010', '0001011', '10'], 'pro': ['010'], 'con': ['010'], 'alreadi': ['010', '011', '0001000'], 'suggest': ['010'], 'propos': ['010'], 'think': ['010', '0001010'], 'fine': ['010'], 'might': ['010', '0001101'], 'charg': ['010', '0001001'], '200': ['010'], 'per': ['010', '011'], 'respons': ['010'], 'caus': ['010', '0001001'], 'care': ['010'], 'sure': ['010', '0001010'], 'consider': ['010'], 'still': ['010', '00101', '011'], 'fee': ['010', '00101'], 'total': ['010'], 'offset': ['010'], 'post': ['010'], 'inconsider': ['010', '0001100'], 'renter': ['010', '0001100'], 'websit': ['010'], 'know': ['010', '0001010'], 'continu': ['010'], 'visitor': ['010'], 'proven': ['010'], 'other': ['010'], 'worth': ['010', '00101', '0001000'], 'headach': ['010'], 'southern': ['011'], 'california': ['011', '00100'], 'tri': ['011', '010', '00110', '011'], 'skyrocket': ['011'], 'price': ['011', '10', '00110', '011'], 'gasolin': ['011'], 'averag': ['011'], '87': ['011'], 'octan': ['011'], 'economi': ['011'], 'ga': ['011'], '222': ['011'], 'higher': ['011'], 'today': ['011'], '12': ['011'], 'month': ['011', '011', '00111'], 'lowest': ['011'], 'southland': ['011'], '209': ['011'], 'gallon': ['011', '00111'], 'seashel': ['011'], 'station': ['011'], 'arcadia': ['011'], 'everett': ['011'], 'reason': ['011', '0001011'], 'cheaper': ['011'], 'elsewher': ['011'], 'reduc': ['011', '00101'], 'pas': ['011'], 'custom': ['011', '0001000'], 'line': ['011', '0001100'], 'often': ['011'], 'run': ['011', '011', '00101'], '20': ['011', '0001010'], 'vehicl': ['011', '0001000'], 'long': ['011'], 'sever': ['011', '0001000'], 'block': ['011', '0001000'], 'traffic': ['011', '10', '0001000'], 'horsetrail': ['011'], 'drive': ['011', '0001000'], 'barco': ['011'], 'away': ['011', '00111'], '214': ['011'], 'rather': ['011'], 'wait': ['011', '00100'], '5': ['011', '00111'], 'cent': ['011', '00111'], 'ok': ['011'], 'cours': ['011', '0001100'], 'mind': ['011'], 'young': ['011'], 'man': ['011', '00101', '00101', '00110'], 'pump': ['011'], 'ask': ['011', '0001001'], 'penni': ['011'], 'count': ['011'], '99': ['011'], 'bummer': ['011'], '1': ['011', '00110'], 'pretti': ['011', '0001001'], 'cheap': ['011'], 'though': ['011'], 'eight': ['011', '0001010', '010'], 'pay': ['011', '011', '00110'], 'much': ['011', '011', '0001001'], 'fill': ['011', '0001100'], 'tank': ['011'], 'kill': ['011'], 'groceri': ['011'], 'around': ['011'], 'neighborhood': ['011', '0001010'], 'show': ['011'], 'wheel': ['011', '0001000'], 'joke': ['00111'], 'lo': ['00111', '00100'], 'angel': ['00111', '00100'], 'read': ['00111'], 'everyon': ['00111', '00100', '00100'], 'tv': ['00111', '010', '00110'], 'goe': ['00111', '00111'], 'popular': ['00111', '0001000'], 'materi': ['00111'], 'comic': ['00111'], 'book': ['00111', '00100'], 'magazin': ['00111', '10', '011'], 'guid': ['00111'], 'librari': ['00111'], 'wash': ['00111'], 'explain': ['00111'], 'annual': ['00111', '00111'], 'festiv': ['00111'], 'west': ['00111', '00100'], 'sold': ['00111'], 'half': ['00111', '10', '00101', '011'], 'hour': ['00111', '00101', '0001010', '010', '00101'], 'space': ['00111'], 'becom': ['00111'], 'avail': ['00111'], 'outdoor': ['00111'], 'sponsor': ['00111'], 'newspap': ['00111', '00100'], 'occur': ['00111', '00110', '010'], 'april': ['00111'], 'weekend': ['00111', '00111'], 'attend': ['00111'], 'estim': ['00111'], '70000': ['00111'], '75000': ['00111'], 'sunday': ['00111'], 'featur': ['00111'], '280': ['00111'], 'exhibitor': ['00111'], '90': ['00111'], 'talk': ['00111', '010', '00100'], 'given': ['00111'], 'author': ['00111'], 'audienc': ['00111'], 'question': ['00111'], 'answer': ['00111'], 'period': ['00111', '0001001'], 'autograph': ['00111'], 'seeker': ['00111'], 'sought': ['00111'], '150': ['00111', '0001000'], 'food': ['00111', '10', '00101'], 'court': ['00111'], 'kind': ['00111', '00110'], 'ethnic': ['00111'], 'american': ['00111'], 'hamburg': ['00111'], 'hawaiian': ['00111'], 'shave': ['00111'], 'ice': ['00111', '0001000'], 'drink': ['00111'], 'except': ['00111', '00100'], '7': ['00111', '011'], 'free': ['00111'], 'avoid': ['00111', '00100'], 'sneak': ['00111'], 'sandwich': ['00111'], 'drove': ['00111', '011'], 'san': ['00111'], 'francisco': ['00111'], 'sixth': ['00111'], 'husband': ['00111'], 'fantast': ['00111'], 'great': ['00111', '0001000'], 'among': ['00111'], 'mani': ['00111', '00111'], 'good': ['00111', '00101'], 'deal': ['00111', '0001000'], 'idea': ['00111', '00101'], 'nobodi': ['00111'], 'knew': ['00111', '00111'], 'succeed': ['00111'], 'although': ['00111', '0001000'], 'u': ['00111'], 'embrac': ['00111'], 'angeleno': ['00111'], 'unpredict': ['00111'], 'founder': ['00111'], 'inmat': ['0001000'], 'releas': ['0001000'], 'correct': ['0001000', '0001001'], 'offic': ['0001000', '011'], 'held': ['0001000'], 'tower': ['0001000'], 'state': ['0001000', '10', '011'], 'prison': ['0001000'], 'complex': ['0001000'], 'captur': ['0001000'], 'quell': ['0001000'], 'fight': ['0001000'], 'main': ['0001000'], 'dine': ['0001000'], 'room': ['0001000'], 'erupt': ['0001000'], 'discov': ['0001000'], 'candi': ['0001000', '00101'], 'ration': ['0001000'], 'cut': ['0001000', '00100'], 'barter': ['0001000'], 'item': ['0001000'], 'trade': ['0001000'], 'cigarett': ['0001000'], 'cigar': ['0001000'], 'stationeri': ['0001000'], 'legal': ['0001000'], 'dictionari': ['0001000'], 'necessari': ['0001000', '00100'], 'back': ['0001000', '00110', '0001101', '000010010', '0001011'], 'luxuri': ['0001000'], 'order': ['0001000', '011'], 'provid': ['0001000'], 'basic': ['0001000'], 'soap': ['0001000'], 'razor': ['0001000'], 'toilet': ['0001000'], 'paper': ['0001000'], 'berserk': ['0001000'], 'reduct': ['0001000'], 'threw': ['0001000', '011'], 'plate': ['0001000'], 'silverwar': ['0001000'], 'door': ['0001000', '00110', '10', '00101'], 'window': ['0001000'], 'guard': ['0001000'], 'grab': ['0001000'], 'haul': ['0001000', '00111'], 'secur': ['0001000', '00100'], 'sent': ['0001000'], 'messag': ['0001000'], 'demand': ['0001000'], 'big': ['0001000', '00111', '0001100', '00101'], 'bag': ['0001000', '00111'], 'exchang': ['0001000'], 'spare': ['0001000'], 'warden': ['0001000'], 'compli': ['0001000'], 'negoti': ['0001000'], 'approv': ['0001000'], 'restor': ['0001000'], 'return': ['0001000'], 'administr': ['0001000'], 'daili': ['0001000'], 'allot': ['0001000'], '75': ['0001000'], 'sam': ['0001001'], 'unemploy': ['0001001'], 'piano': ['0001001', '00101'], 'tuner': ['0001001'], 'second': ['0001001'], 'thing': ['0001001', '00111', '011'], 'ever': ['0001001'], 'life': ['0001001', '00100', '010', '011'], 'first': ['0001001', '00110', '10'], 'afghan': ['0001001'], 'blanket': ['0001001'], 'church': ['0001001'], 'raffl': ['0001001'], '25': ['0001001'], 'bigger': ['0001001'], '120000': ['0001001'], 'cube': ['0001001'], 'lotteri': ['0001001'], 'game': ['0001001'], 'win': ['0001001'], 'contest': ['0001001'], 'must': ['0001001', '011'], 'guess': ['0001001'], 'number': ['0001001'], 'spin': ['0001001'], 'six': ['0001001', '011'], 'x': ['0001001'], '50': ['0001001', '0001000', '00100'], '100': ['0001001'], '500': ['0001001', '00110'], '0': ['0001001'], 'select': ['0001001'], 'variabl': ['0001001'], 'greater': ['0001001'], 'appear': ['0001001'], 'guarante': ['0001001'], 'correctli': ['0001001'], 'choos': ['0001001'], 'sign': ['0001001'], 'hill': ['0001001'], 'lake': ['0001001'], 'avenu': ['0001001', '010'], 'teenag': ['0001001'], 'boy': ['0001001', '00110'], 'chang': ['0001001', '0001000', '00100', '10'], 'channel': ['0001001'], 'tough': ['0001001'], 'decis': ['0001001'], 'flip': ['0001001'], 'coin': ['0001001'], 'head': ['0001001', '00101'], 'pick': ['0001001', '00101'], '76': ['0001001'], 'teen': ['0001001'], 'click': ['0001001'], '120': ['0001001'], 'sixti': ['0001001'], 'jump': ['0001001'], 'joy': ['0001001'], 'dreamili': ['0001001'], 'left': ['0001001', '00101'], 'studio': ['0001001'], 'excitedli': ['0001001'], 'cell': ['0001001'], 'phone': ['0001001'], 'cross': ['0001001'], 'got': ['0001001', '0001000', '000010000', '000010111', '000010011'], 'hit': ['0001001'], 'littl': ['0001001', '011'], 'sport': ['0001001'], 'slowli': ['0001001'], 'better': ['0001001', '00101'], 'hospit': ['0001001', '010'], 'bill': ['0001001'], '110000': ['0001001'], 'insur': ['0001001'], 'compani': ['0001001'], 'su': ['0001001'], '9000': ['0001001'], 'repair': ['0001001'], 'feder': ['0001001', '011'], 'tax': ['0001001', '10'], 'play': ['0001001', '00101'], 'unlucki': ['0001001'], 'sara': ['0001010'], 'smith': ['0001010'], 'pasadena': ['0001010'], 'shop': ['0001010', '00101'], '303': ['0001010'], 'n': ['0001010'], 'foothil': ['0001010'], 'sinc': ['0001010'], '199': ['0001010'], '2': ['0001010'], 'marri': ['0001010', '011'], 'john': ['0001010'], 'seven': ['0001010'], 'child': ['0001010'], 'bob': ['0001010'], 'five': ['0001010', '010', '011', '10'], 'nanci': ['0001010'], 'own': ['0001010'], 'blue': ['0001010'], 'toyola': ['0001010'], '9': ['0001010'], 'barget': ['0001010'], 'depart': ['0001010', '00101'], 'holiday': ['0001010'], 'sale': ['0001010'], 'slice': ['0001010'], 'toaster': ['0001010'], '2995': ['0001010'], 'plu': ['0001010'], 'regular': ['0001010'], '3995': ['0001010'], 'paid': ['0001010', '0001100'], 'check': ['0001010'], 'way': ['0001010', '0001100'], 'milkplu': ['0001010'], 'nonfat': ['0001010'], 'milk': ['0001010'], '350': ['0001010'], 'arriv': ['0001010'], 'kid': ['0001010', '011'], 'sleep': ['0001010'], 'woke': ['0001010'], 'made': ['0001010'], 'hot': ['0001010'], 'nutriti': ['0001010'], 'breakfast': ['0001010'], '24': ['0001011'], 'taken': ['0001011'], 'counti': ['0001011'], 'jail': ['0001011'], 'lead': ['0001011'], 'freeway': ['0001011'], 'chase': ['0001011'], 'stolen': ['0001011'], 'suv': ['0001011'], 'end': ['0001011', '010'], 'downtown': ['0001011'], 'front': ['0001011'], 'spring': ['0001011'], 'hotel': ['0001011'], 'unev': ['0001011'], 'empti': ['0001011'], 'bottl': ['0001011', '00100'], 'whiskey': ['0001011'], 'driver': ['0001011'], 'start': ['0001011'], 'happen': ['0001011', '010'], 'ran': ['0001011'], 'fire': ['0001011', '10', '011'], 'hydrant': ['0001011'], 'water': ['0001011'], 'spew': ['0001011'], 'geyser': ['0001011'], 'ruin': ['0001011'], 'cart': ['0001011', '00100'], 'vendor': ['0001011'], 'put': ['0001011', '0001100'], 'outsid': ['0001011'], 'attract': ['0001011'], 'bookstor': ['0001011'], 'hurriedli': ['0001011'], 'turn': ['0001011'], 'onto': ['0001011'], 'grand': ['0001011'], 'bang': ['0001011'], 'side': ['0001011'], 'stand': ['0001011'], 'crosswalk': ['0001011'], 'halt': ['0001011'], 'slam': ['0001011'], 'brake': ['0001011'], 'collis': ['0001011'], 'uninjur': ['0001011'], 'pursu': ['0001011'], 'differ': ['0001011', '011'], 'direct': ['0001011'], 'lucki': ['0001011', '10', '010'], 'earli': ['0001011'], 'enough': ['0001011'], 'damag': ['0001011'], 'minor': ['0001011'], 'resum': ['0001011'], 'find': ['0001011'], 'come': ['0001011', '010', '010', '10'], 'full': ['0001011', '010', '010'], 'plow': ['0001011'], 'wear': ['0001011'], 'seatbelt': ['0001011'], 'slump': ['0001011'], 'behind': ['0001011'], 'steer': ['0001011'], 'proprietor': ['0001011'], 'newsstand': ['0001011'], 'yell': ['0001011'], 'shake': ['0001011'], 'call': ['0001011', '010', '10'], 'ambul': ['0001011'], 'failur': ['0001011'], 'yield': ['0001011'], 'influenc': ['0001011'], 'mountain': ['0001100'], 'town': ['0001100'], 'canton': ['0001100'], 'elev': ['0001100'], '6000': ['0001100'], 'foot': ['0001100', '10'], 'surround': ['0001100'], 'thick': ['0001100'], 'underbrush': ['0001100'], 'pine': ['0001100'], 'tree': ['0001100'], 'drought': ['0001100'], 'plant': ['0001100'], 'major': ['0001100'], 'hazard': ['0001100'], 'thousand': ['0001100'], 'ton': ['0001100', '10', '010'], 'remov': ['0001100'], 'minimum': ['0001100'], 'cost': ['0001100'], '3': ['0001100'], 'million': ['0001100', '011', '10'], 'brush': ['0001100'], 'toppl': ['0001100'], 'clear': ['0001100'], 'nonflamm': ['0001100'], 'area': ['0001100'], 'safe': ['0001100'], '4000': ['0001100'], 'look': ['0001100'], 'forward': ['0001100'], 'help': ['0001100', '10'], 'surviv': ['0001100'], 'futur': ['0001100'], 'inferno': ['0001100'], 'truck': ['0001100', '011'], 'bad': ['0001100'], 'dirt': ['0001100'], 'biker': ['0001100'], 'person': ['0001100', '010'], 'playground': ['0001100'], 'recent': ['0001100'], 'burn': ['0001100'], 'acr': ['0001100'], 'destroy': ['0001100'], '11': ['0001100'], 'nearbi': ['0001100'], 'hamilton': ['0001100'], 'rage': ['0001100'], 'toward': ['0001100'], 'sudden': ['0001100'], 'rainstorm': ['0001100'], 'twice': ['0001100', '10'], 'massiv': ['0001100'], 'oper': ['0001100'], 'nineti': ['0001100'], 'fund': ['0001100'], 'unfortun': ['0001100'], 'privat': ['0001100'], 'properti': ['0001100'], 'rang': ['0001100'], 'appli': ['0001100'], 'loan': ['0001100'], 'thelma': ['0001100'], '65': ['0001100'], 'widow': ['0001100', '10'], 'social': ['0001100'], 'govern': ['0001100'], 'suppos': ['0001100'], 'planner': ['0001100'], 'ought': ['0001100'], 'woman': ['0001101'], 'die': ['0001101'], 'appar': ['0001101'], 'murder': ['0001101'], 'suicid': ['0001101'], 'last': ['0001101'], 'altadena': ['0001101'], '74': ['0001101'], 'domin': ['0001101'], 'vittorio': ['0001101'], '70': ['0001101'], 'wife': ['0001101'], 'victoria': ['0001101'], 'fact': ['0001101'], 'th': ['0001101'], 'anniversari': ['0001101'], 'accord': ['0001101'], 'mr': ['0001101'], 'allen': ['0001101'], 'childless': ['0001101'], 'close': ['0001101'], 'friend': ['0001101', '0001110'], 'retir': ['0001101'], 'carpent': ['0001101'], 'emphysema': ['0001101'], 'blind': ['0001101'], 'eye': ['0001101'], 'cataract': ['0001101'], 'diabet': ['0001101'], 'amput': ['0001101'], 'complic': ['0001101'], 'diseas': ['0001101'], 'eyesight': ['0001101'], 'complet': ['0001101'], 'gone': ['0001101'], 'dom': ['0001101'], 'alway': ['0001101', '0001110'], 'light': ['0001101', '0001111'], 'bulb': ['0001101'], 'fix': ['0001101'], 'applianc': ['0001101'], 'friendli': ['0001101'], 'halloween': ['0001101'], 'hand': ['0001101'], 'fresh': ['0001101'], 'fruit': ['0001101'], 'vicki': ['0001101'], 'seem': ['0001101', '0001110'], 'quieter': ['0001101'], 'nicest': ['0001101'], 'le': ['0001101'], 'sicker': ['0001101'], 'convers': ['0001101'], 'steadili': ['0001101'], 'shorter': ['0001101'], 'lose': ['0001101'], 'interest': ['0001101'], 'pain': ['0001101'], 'either': ['0001101'], 'never': ['0001101'], 'deliv': ['0001101'], 'local': ['0001101'], 'agenc': ['0001101'], 'heard': ['0001101'], 'gunshot': ['0001101'], 'scare': ['0001101'], 'death': ['0001101'], 'immedi': ['0001101'], 'sad': ['0001101'], 'togeth': ['0001101'], 'sick': ['0001101'], 'alon': ['0001101'], 'world': ['0001101', '0001110'], 'samantha': ['0001110'], 'tire': ['0001111', '0001110'], 'clockwork': ['0001110'], 'landlord': ['0001110'], 'rais': ['0001110'], 'move': ['0001110'], 'slammer': ['0001110'], 'saxophonist': ['0001110'], 'day': ['0001111', '0001110'], 'whole': ['0001110'], 'band': ['0001110'], 'saxophon': ['0001110'], 'permit': ['0001110'], 'job': ['0001111', '0001110'], 'relat': ['0001110'], 'told': ['0001110'], 'unhappi': ['0001110'], 'happi': ['0001110'], 'howard': ['0001110'], 'middl': ['0001110'], 'age': ['0001110'], 'chef': ['0001110'], 'best': ['0001110'], 'leftov': ['0001110'], 'pianist': ['0001110'], 'delight': ['0001110'], 'mechan': ['0001110'], 'tune': ['0001110'], 'up': ['0001110'], 'oil': ['0001110'], 'latest': ['0001110'], 'birder': ['0001110'], 'bird': ['0001110'], 'binocular': ['0001110'], 'attitud': ['0001110'], 'saw': ['0001110'], 'player': ['0001110'], 'irrit': ['0001110'], 'yet': ['0001110'], 'roof': ['0001110'], 'complain': ['0001110'], 'wrong': ['0001110'], 'consist': ['0001111'], 'volunt': ['0001111'], 'drizzl': ['0001111'], 'clean': ['0001111'], 'carson': ['0001111'], 'creek': ['0001111'], 'nine': ['0001111'], 'debri': ['0001111'], 'done': ['0001111'], 'smile': ['0001111'], 'alan': ['0001111'], 'specter': ['0001111'], 'event': ['0001111'], 'schedul': ['0001111'], 'hope': ['0001111'], 'garbag': ['0001111'], 'shape': ['0001111'], 'size': ['0001111'], 'can': ['0001111'], 'bicycl': ['0001111'], 'auto': ['0001111'], 'batteri': ['0001111'], 'sofa': ['0001111'], 'furnitur': ['0001111'], 'cloth': ['0001111'], 'bowl': ['0001111'], 'ball': ['0001111'], 'plastic': ['0001111'], 'doll': ['0001111'], 'babi': ['0001111'], 'carriag': ['0001111'], 'antenna': ['0001111'], 'portabl': ['0001111'], 'radio': ['0001111'], 'golf': ['0001111'], 'set': ['0001111'], 'backbreak': ['0001111'], 'group': ['0001111'], 'cub': ['0001111'], 'scout': ['0001111'], 'environment': ['0001111'], 'bay': ['0001111'], 'whale': ['0001111'], 'concern': ['0001111'], 'retire': ['0001111'], 'assist': ['0001111'], 'issu': ['0001111'], 'boot': ['0001111'], 'glove': ['0001111'], 'gear': ['0001111'], 'along': ['0001111'], 'stretch': ['0001111'], 'streamb': ['0001111'], 'roadsid': ['0001111'], 'take': ['0001111'], 'landfil': ['0001111'], 'yellow': ['0001111'], 'found': ['0001111'], 'anyth': ['0001111'], 'valu': ['0001111'], 'ear': ['0001111'], 'thought': ['0001111'], 'dollar': ['0001111'], 'shini': ['0001111'], 'sell': ['0001111'], 'donat': ['0001111'], 'proce': ['0001111'], 'tripl': ['0001111'], 'scoop': ['0001111'], 'cream': ['0001111'], 'cone': ['0001111'], 'rest': ['0001111']}\n"
          ]
        }
      ],
      "source": [
        "print(BSBI.finalInvertedIndex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Report:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Steps:\n",
        "\n",
        "$1.$ For this project at first I revied my previous home works, and most of my codes was compatible and I use from them.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "$2.$ Then I read about gamma coding in geeksforgeeks and I implemeted it.(it was not challenging, we had it's defenition and it was simple)\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "$3.$ Then I read our slides about BSBI that said for memory limitation we can't load all documents to ram, so we use disk. We have some blocks in our disk that every block has a little inverted index, in my code I will load three document from disk to memory then I will generate it's inverted index and then write it to a block, then in BSBI we will read these blocks that every one of them is a inverted index, then I will merge them.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "$4.$ There are some Notes about BSBI :\n",
        "\n",
        "1. We assumed that we can load and save final inverted index to our memory.\n",
        "2. As I read all documents one by one, so my posting lists in all bocks are sorted, so I don't need sort them.\n",
        "3. As you know every inverted index that I saved to disk are small so I didn't save differences of doc Ids to my posting lists, but in final inverted index I save differences or gaps between document IDs.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "$5.$ I assembled all these component and in this step I forced to write a Util for giving some functionality to me.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "$6.$ I faced a issue in my code, in HW1 in inverted index we saved positions but here we did'nt need to them, so I deleted all of them and I will keep docId in posting lists\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "$7.$ In last step I write a documentation for my code, but for better style and a formal language I gave them and my classes to chatGpt I helped me to generate documents, at last I revise all things and merge all of them and write my document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Our course slides\n",
        "2. https://www.nltk.org/\n",
        "3. https://chat.openai.com/\n",
        "4. https://www.geeksforgeeks.org/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
